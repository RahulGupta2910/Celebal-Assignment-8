# Celebal-Assignment-8

## ** Objective**
To load NYC Yellow Taxi data into Azure Data Lake and analyze it using PySpark in Databricks by performing data transformations, revenue calculations, aggregations, and real-time insights, along with flattening JSON files and storing them as external Parquet tables.

---

## ** Technologies Used**

- **Apache Spark (PySpark)**
- **Azure Databricks**
- **Azure Data Lake Storage Gen2 / Blob Storage**
- **DBFS**
- **Parquet Format**
- **Real-Time Streaming Window Functions** (for time-based queries)

---

## ** Outcomes**

- Gained experience in **real-time data analysis** using PySpark.
- Applied **moving window**, **groupBy**, and **aggregation** logic for business insights.
- Learned to flatten JSON and write to **external parquet** tables for future scalability.

---

## ** Learning Highlights**

- Hands-on with **PySpark transformations and aggregations**
- Understand Databricks workflows for **batch and real-time analytics**
- Best practices for **schema enforcement** and **data validation**
- Creating **external tables** for consumption by BI tools

---

## ** Prerequisites**

- Azure subscription with:
  - **Azure Data Lake Storage Gen2**
  - **Azure Databricks Workspace**
- Installed libraries:
  - `pyspark`
  - `json`
  - `pandas` (for intermediate validation)
